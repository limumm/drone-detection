{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "# 定义查找文件名的函数\n",
    "def find_file(filename, search_path):\n",
    "    result = []\n",
    "    # 遍历文件夹及其子文件夹\n",
    "    for root, dir, files in os.walk(search_path):\n",
    "        if filename in files:\n",
    "            result.append(os.path.join(root, filename))\n",
    "    return result\n",
    "\n",
    "# 查找文件夹及其子文件夹中名为000001.jpg的图片\n",
    "file_paths = find_file('000001.jpg', '/media/limumu/ADC4EA8E9E19D40E/DDProj/test_res/detect+tracking_res')\n",
    "\n",
    "# 复制所有路径的图片到一个新的文件夹first_jpgs\n",
    "for i, path in enumerate(file_paths):\n",
    "    new_filename = f\"{int(time.time())}_{i}.jpg\"\n",
    "    shutil.copy(path, f'/media/limumu/ADC4EA8E9E19D40E/DDProj/first_jpgs/{new_filename}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_75155/611228894.py:9: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage = elem.storage()._new_shared(numel)\n",
      "/tmp/ipykernel_75155/611228894.py:12: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [2, 5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:26.)\n",
      "  torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0231, -0.6411, -1.7186, -0.3180,  0.0420],\n",
       "        [ 1.0701, -0.5758, -1.4116, -0.0942, -0.3780]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a, b = torch.randn([5]), torch.randn([5])\n",
    "batch = [a, b]\n",
    "elem = batch[0]\n",
    "\n",
    "# In case torch.utils.data.get_worker_info() is not None\n",
    "numel = sum(x.numel() for x in batch)\n",
    "storage = elem.storage()._new_shared(numel)\n",
    "out = elem.new(storage)\n",
    "\n",
    "torch.stack(batch, 0, out=out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
